{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fedc37-4d78-4dad-9c41-2cd5da6ac511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7214e95-a11c-4c57-9e2a-ebe15450bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ac1951-2d6a-49cb-abe4-e5e6a18ff7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fashionable\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"25G\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"512m\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfae2911-f34b-49c0-9a33-2510aaeca044",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_trans_pq = r'D:\\data\\h&m\\transactions_train.parquet'\n",
    "# src_article_pq = r'D:\\data\\h&m\\articles.parquet'\n",
    "# src_cust_pq = r'D:\\data\\h&m\\customers.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c18ea17-caae-4def-9531-8195e1b6cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = spark.read.parquet(src_trans_pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bf5307-b883-4a58-8f92-1a5071c56134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa78c87aacba903d16f393da3edeca27d62e642b1a639...</td>\n",
       "      <td>0706016003</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa78c87aacba903d16f393da3edeca27d62e642b1a639...</td>\n",
       "      <td>0706016001</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa78c87aacba903d16f393da3edeca27d62e642b1a639...</td>\n",
       "      <td>0682236013</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa78c87aacba903d16f393da3edeca27d62e642b1a639...</td>\n",
       "      <td>0706016016</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa7a0483dd5b9e395d95324dcbfeb617af9800f39487d...</td>\n",
       "      <td>0783335003</td>\n",
       "      <td>0.020322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_dat                                        customer_id  article_id  \\\n",
       "0  2019-11-29  aaa78c87aacba903d16f393da3edeca27d62e642b1a639...  0706016003   \n",
       "1  2019-11-29  aaa78c87aacba903d16f393da3edeca27d62e642b1a639...  0706016001   \n",
       "2  2019-11-29  aaa78c87aacba903d16f393da3edeca27d62e642b1a639...  0682236013   \n",
       "3  2019-11-29  aaa78c87aacba903d16f393da3edeca27d62e642b1a639...  0706016016   \n",
       "4  2019-11-29  aaa7a0483dd5b9e395d95324dcbfeb617af9800f39487d...  0783335003   \n",
       "\n",
       "      price  sales_channel_id  \n",
       "0  0.025288                 2  \n",
       "1  0.025288                 2  \n",
       "2  0.018983                 2  \n",
       "3  0.025288                 2  \n",
       "4  0.020322                 2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0292616f-f0ba-4c79-b75e-b4caf2a86351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31788324"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d0f28c0-239f-449d-b0ed-4d041936edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aec8b83-b330-4299-965f-6da104f4231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexer = [StringIndexer(inputCol=column, outputCol=column+\"_idx\") for column in ['customer_id', 'article_id']]\n",
    "# pipeline = Pipeline(stages=indexer)\n",
    "# df_trans = pipeline.fit(df_trans).transform(df_trans)\n",
    "\n",
    "custIndexer = StringIndexer().setInputCol('customer_id').setOutputCol('customer_id_idx')\n",
    "articleIndexer = StringIndexer().setInputCol('article_id').setOutputCol('article_id_idx')\n",
    "pipeline = Pipeline(stages=[custIndexer, articleIndexer])\n",
    "\n",
    "df_trans = pipeline.fit(df_trans).transform(df_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e5dd73-ffe6-4be3-8828-dc3f419c0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_map = df_trans.select('customer_id_idx', 'customer_id')\n",
    "article_map = df_trans.select('article_id_idx', 'article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a39007-257a-4747-828e-c0eb13b4a720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>customer_id_idx</th>\n",
       "      <th>article_id_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa78c87aacba903d16f393da3edeca27d62e642b1a639...</td>\n",
       "      <td>0706016003</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>2</td>\n",
       "      <td>340255.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa78c87aacba903d16f393da3edeca27d62e642b1a639...</td>\n",
       "      <td>0706016001</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>2</td>\n",
       "      <td>340255.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa78c87aacba903d16f393da3edeca27d62e642b1a639...</td>\n",
       "      <td>0682236013</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>2</td>\n",
       "      <td>340255.0</td>\n",
       "      <td>17656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa78c87aacba903d16f393da3edeca27d62e642b1a639...</td>\n",
       "      <td>0706016016</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>2</td>\n",
       "      <td>340255.0</td>\n",
       "      <td>6159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>aaa7a0483dd5b9e395d95324dcbfeb617af9800f39487d...</td>\n",
       "      <td>0783335003</td>\n",
       "      <td>0.020322</td>\n",
       "      <td>2</td>\n",
       "      <td>1318380.0</td>\n",
       "      <td>44019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_dat                                        customer_id  article_id  \\\n",
       "0  2019-11-29  aaa78c87aacba903d16f393da3edeca27d62e642b1a639...  0706016003   \n",
       "1  2019-11-29  aaa78c87aacba903d16f393da3edeca27d62e642b1a639...  0706016001   \n",
       "2  2019-11-29  aaa78c87aacba903d16f393da3edeca27d62e642b1a639...  0682236013   \n",
       "3  2019-11-29  aaa78c87aacba903d16f393da3edeca27d62e642b1a639...  0706016016   \n",
       "4  2019-11-29  aaa7a0483dd5b9e395d95324dcbfeb617af9800f39487d...  0783335003   \n",
       "\n",
       "      price  sales_channel_id  customer_id_idx  article_id_idx  \n",
       "0  0.025288                 2         340255.0             9.0  \n",
       "1  0.025288                 2         340255.0             0.0  \n",
       "2  0.018983                 2         340255.0         17656.0  \n",
       "3  0.025288                 2         340255.0          6159.0  \n",
       "4  0.020322                 2        1318380.0         44019.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c36d7db3-509f-436d-8804-2f099a2f7c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- t_dat: date (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- article_id: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- sales_channel_id: integer (nullable = true)\n",
      " |-- customer_id_idx: double (nullable = false)\n",
      " |-- article_id_idx: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trans.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e0142-34b4-4401-8104-0e7ab55cb670",
   "metadata": {},
   "source": [
    "### Alternating Least Squares (ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3096cf71-4134-4df5-a23a-ba32108e38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bb4188b-cd20-4cda-ba2b-678a9530f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = df_trans.withColumn('rating', F.lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f7a02b-4517-4cb7-b040-5aa4f6e2d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = df_trans.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a868f93-e665-464d-a15f-67d851f1d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(nonnegative=True)\\\n",
    "    .setMaxIter(5)\\\n",
    "    .setRegParam(0.01)\\\n",
    "    .setUserCol('customer_id_idx')\\\n",
    "    .setItemCol('article_id_idx')\\\n",
    "    .setRatingCol('rating')\\\n",
    "    .setColdStartStrategy('drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c4e295f-066e-46e6-81fd-a354ba4fa2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: alpha for implicit preference (default: 1.0)\n",
      "blockSize: block size for stacking input data in matrices. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data. (default: 4096)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "coldStartStrategy: strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'. (default: nan, current: drop)\n",
      "finalStorageLevel: StorageLevel for ALS model factors. (default: MEMORY_AND_DISK)\n",
      "implicitPrefs: whether to use implicit preference (default: False)\n",
      "intermediateStorageLevel: StorageLevel for intermediate datasets. Cannot be 'NONE'. (default: MEMORY_AND_DISK)\n",
      "itemCol: column name for item ids. Ids must be within the integer value range. (default: item, current: article_id_idx)\n",
      "maxIter: max number of iterations (>= 0). (default: 10, current: 5)\n",
      "nonnegative: whether to use nonnegative constraint for least squares (default: False, current: True)\n",
      "numItemBlocks: number of item blocks (default: 10)\n",
      "numUserBlocks: number of user blocks (default: 10)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "rank: rank of the factorization (default: 10)\n",
      "ratingCol: column name for ratings (default: rating, current: rating)\n",
      "regParam: regularization parameter (>= 0). (default: 0.1, current: 0.01)\n",
      "seed: random seed. (default: 2942448487523106480)\n",
      "userCol: column name for user ids. Ids must be within the integer value range. (default: user, current: customer_id_idx)\n"
     ]
    }
   ],
   "source": [
    "print(als.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe93cc12-c8ab-447e-b1d1-b8ccab64e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45e63665-0e8c-42a4-a9ee-4fe4bf2898ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.25513100624084\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "alsModel = als.fit(training)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d85cd82-ad50-4cf4-8c5a-92f9f4bea64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053290367126464844\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "predictions = alsModel.transform(test)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18006b3f-1a38-402b-80de-d15487a9ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_rec = alsModel.recommendForAllUsers(12).selectExpr(\"customer_id_idx\", \"explode(recommendations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa23185f-2b57-42be-842c-2efc12da7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# alsModel.recommendForAllItems(10).selectExpr(\"article_id_idx\", \"explode(recommendations)\").show()\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73ae664d-e456-40b0-9737-c38251986023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- t_dat: date (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- article_id: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- sales_channel_id: integer (nullable = true)\n",
      " |-- customer_id_idx: double (nullable = false)\n",
      " |-- article_id_idx: double (nullable = false)\n",
      " |-- rating: integer (nullable = false)\n",
      " |-- prediction: float (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de8537-8a51-4c1e-85ec-5e5ab6b7c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "alsModel.recommendForAllUsers(12).write.mode('overwrite').parquet(r'D:\\data\\h&m\\predictions_001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4183f1-634e-4272-9e8e-3a6ca1a1b441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc69fb-a72d-4fa2-8fc4-f9ac2512928d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96a658f8-5448-4aa4-b468-f4b71db05d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RankingEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10f8858c-c7b5-4ca9-b291-c9a1378a48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RankingEvaluator()\\\n",
    "    .setPredictionCol('prediction')\\\n",
    "    .setLabelCol('rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2c768-acc0-4b3b-ba25-bb56a6e130c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_pred = predictions\\\n",
    "    .groupBy('customer_id')\\\n",
    "    .agg(F.collect_set('prediction').alias('prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f086e20-67d0-4d02-904c-5954839c256f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column prediction must be of type equal to one of the following types: [array<double>, array<double>] but was actually of type float.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3316/4263280950.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"precisionAtK\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: requirement failed: Column prediction must be of type equal to one of the following types: [array<double>, array<double>] but was actually of type float."
     ]
    }
   ],
   "source": [
    "evaluator.evaluate(predictions, {evaluator.metricName: \"precisionAtK\", evaluator.k: 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e984ea4-05a6-467e-84f3-733022188f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29eeed5-ba84-435c-b4b9-f6e56737f5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = RankingMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa247c6-472d-435e-b75a-96afd8c0884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RankingEvaluator()\\\n",
    "    .setMetricName('rmse')\\\n",
    "    .setLabelCol('rating')\\\n",
    "    .setPredictionCol('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513eec3a-a176-4636-a454-bdf4ed3246e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac6c26-3c9f-4dd6-952e-38f2e787778c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b75d8-e5dc-44a7-803c-75999f7b56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ca058-ba49-417a-a73a-d56bfb5d82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator()\\\n",
    "    .setMetricName('rmse')\\\n",
    "    .setLabelCol('rating')\\\n",
    "    .setPredictionCol('prediction')\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f282742c-ddcf-46cb-bde3-4adcd5336f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "alsModel.recommendForAllUsers(12).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb9efa-ade4-4065-bfd2-03206c35ed34",
   "metadata": {},
   "source": [
    "Get user recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc3d75-6c72-4ddf-9e94-f7fb08b865d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_rec = alsModel.recommendForAllUsers(12).select #.selectExpr(\"customer_id_idx\", \"explode(recommendations)\")\n",
    "user_rec = alsModel.recommendForAllUsers(12)\\\n",
    "    .select(\"customer_id_idx\", F.explode(\"recommendations\"))\\\n",
    "    .select(F.col('customer_id_idx'), F.col('col.article_id_idx'))\\\n",
    "    .join(cust_map, on='customer_id_idx')\\\n",
    "    .join(article_map, on='article_id_idx')\\\n",
    "    .select('customer_id', 'article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826ceea-2e8c-45c3-8aa1-a47e9d5be840",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rec.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089af11-fae3-47dd-8753-5834b1a6192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import IndexToString\n",
    "# labelReverse = IndexToString().setInputCol('customer_id_idx')\n",
    "# lr = labelReverse.transform(user_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5984d2-40d0-4657-9b81-a5aecf094652",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cust = user_rec\\\n",
    "    .groupBy('customer_id')\\\n",
    "    .agg(F.collect_set('article_id').alias('prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3df55-dd3f-4421-902c-8414e38bbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cust.write.parquet(r'D:\\data\\h&m\\predictions_001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc608a-c4d6-4a22-b826-6579077db20b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
